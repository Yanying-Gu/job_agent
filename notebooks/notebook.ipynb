{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since I can not select job_agent kernel, I need to add the project to the path manually\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path (so imports work without special kernel)\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'job_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Now imports work!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjob_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_prompt_file\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Usage (adjust path relative to notebooks folder)\u001b[39;00m\n\u001b[32m      5\u001b[39m prompt_path = \u001b[33m\"\u001b[39m\u001b[33m../prompts/ai_agent.prompt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'job_agent'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Now imports work!\n",
    "from job_agent import load_prompt_file\n",
    "\n",
    "# Usage (adjust path relative to notebooks folder)\n",
    "prompt_path = \"../prompts/ai_agent.prompt\"\n",
    "prompt = load_prompt_file(prompt_path)\n",
    "\n",
    "if prompt:\n",
    "    print(prompt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load output & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MATCHED PROJECTS\n",
      "====================================================================================================\n",
      "\n",
      "1. Adaptive Decision Automation Platform for Global Asset Management\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  Led the development of a dynamic, machine learning-driven decision engine leveraging AWS\n",
      "  SageMaker, transforming complex business requirements into scalable AI models with comprehensive\n",
      "  operational oversight. We achieved a 50% automation rate of maintenance authorization workflows,\n",
      "  leading to accelerated turnaround times, significant operational cost savings, and enhanced\n",
      "  scalability.\n",
      "\n",
      "====================================================================================================\n",
      "MOTIVATION LETTER\n",
      "====================================================================================================\n",
      "\n",
      "---  **Adaptive Decision Automation Platform for Global Asset Management**   Challenge: Legacy\n",
      "decision-making systems relied on inflexible rule sets that hindered operational agility and\n",
      "scalability across international markets.   Initiative: Spearheaded the creation of a dynamic,\n",
      "machine learning-driven decision engine leveraging AWS SageMaker, transforming complex business\n",
      "requirements into scalable AI models with comprehensive operational oversight.   Impact: Rolled out\n",
      "across six nations, enabling a 50% automation rate of maintenance authorization workflows, leading\n",
      "to accelerated turnaround times, significant operational cost savings, and enhanced scalability.\n",
      "---  **Enterprise-scale ML Workflow Modernization for Accelerated Deployment**   Challenge:\n",
      "Disparate data pipelines and fragmented CI/CD processes created bottlenecks and elevated dependency\n",
      "risks in ML operations.   Initiative: Orchestrated the end-to-end refinement of the ML lifecycle by\n",
      "consolidating data transformations within Snowflake’s Snowpark, adopting SageMaker Pipelines for\n",
      "workflow orchestration, and standardizing continuous integration and delivery with GitLab\n",
      "automation.   Impact: Established a unified, resilient ML platform that dramatically cut deployment\n",
      "cycles, minimized manual errors, and optimized team productivity through process standardization and\n",
      "automation.  ---  **Resource-Optimized AI Deployment Framework on Azure Cloud**   Challenge: A\n",
      "significant reduction in team size necessitated a shift toward efficiency without compromising AI\n",
      "capability or delivery timelines.   Initiative: Designed and delivered a comprehensive Azure-native\n",
      "ML infrastructure using Databricks, Unity Catalog, MLflow, and Azure DevOps, while coordinating\n",
      "cross-functional collaboration to drive project success with a lean workforce.   Impact: Launched\n",
      "the organization’s inaugural production-grade ML model on Azure, setting a precedent for scalable,\n",
      "cloud-optimized AI deployments that supported multi-country expansion with minimal resource\n",
      "overhead.  ---  **Intelligent Interactive Approval Assistant to Streamline Maintenance Operations**\n",
      "Challenge: Time-intensive manual approval processes created delays and inefficiencies, limiting\n",
      "responsiveness and operational throughput.   Initiative: Led development of “AI Alex,” an AI-powered\n",
      "virtual assistant utilizing advanced large language models, LangChain integrations, and retrieval-\n",
      "augmented generation pipelines on Azure Databricks, seamlessly integrated with MCP operational\n",
      "tools.   Impact: Successfully transitioned the solution to staging, demonstrating a viable path for\n",
      "reducing human dependency, accelerating approvals, and enhancing collaboration with service partners\n",
      "through intelligent automation.  ---  Let me know if you would like them further tailored for a\n",
      "specific industry vertical or role!\n",
      "\n",
      "====================================================================================================\n",
      "✓ Total Projects: 1\n",
      "✓ Letter Word Count: N/A\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Set width for text wrapping (adjust based on your notebook width)\n",
    "WIDTH = 100\n",
    "\n",
    "def wrap_text(text, width=WIDTH, indent=\"  \"):\n",
    "    \"\"\"Wrap text to specified width with optional indent\"\"\"\n",
    "    wrapper = textwrap.TextWrapper(width=width, initial_indent=indent, \n",
    "                                    subsequent_indent=indent,\n",
    "                                    break_long_words=False,\n",
    "                                    break_on_hyphens=False)\n",
    "    return \"\\n\".join(wrapper.wrap(text))\n",
    "\n",
    "# Load and parse the JSON file\n",
    "with open(\"output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    file_content = f.read()\n",
    "    \n",
    "try:\n",
    "    raw_data = json.loads(file_content)\n",
    "    output_string = raw_data[0][\"output\"]\n",
    "    output_data = json.loads(output_string)\n",
    "    \n",
    "    # Display matched projects with wrapping\n",
    "    print(\"=\" * WIDTH)\n",
    "    print(\"MATCHED PROJECTS\")\n",
    "    print(\"=\" * WIDTH)\n",
    "    \n",
    "    for i, project in enumerate(output_data[\"matched_projects\"], 1):\n",
    "        print(f\"\\n{i}. {project['project_name']}\")\n",
    "        print(\"-\" * WIDTH)\n",
    "        print(wrap_text(project['rewritten_description']))\n",
    "    \n",
    "    # Display motivation letter with wrapping\n",
    "    print(\"\\n\" + \"=\" * WIDTH)\n",
    "    print(\"MOTIVATION LETTER\")\n",
    "    print(\"=\" * WIDTH + \"\\n\")\n",
    "    \n",
    "    # Wrap the full text without indent for letter\n",
    "    letter_text = output_data[\"motivation_letter\"][\"full_text\"]\n",
    "    wrapped_letter = textwrap.fill(letter_text, width=WIDTH)\n",
    "    print(wrapped_letter)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * WIDTH)\n",
    "    print(f\"✓ Total Projects: {len(output_data['matched_projects'])}\")\n",
    "    word_count = output_data[\"motivation_letter\"].get(\"word_count\", \"N/A\")\n",
    "    print(f\"✓ Letter Word Count: {word_count}\")\n",
    "    print(\"=\" * WIDTH)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"✗ JSON Error: {e}\")\n",
    "    print(f\"Content preview: {file_content[:200]}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_structured = {\n",
    "    \"contact\": {\n",
    "        \"phone\": \"+316 10 95 27 90\",\n",
    "        \"email\": \"yanying.gu@gmail.com\",\n",
    "        \"location\": \"Alkmaar (NL)\",\n",
    "        \"linkedin\": \"yanying-gu\"\n",
    "    },\n",
    "    \n",
    "    \"competencies\": [\n",
    "        \"Creative\",\n",
    "        \"Open\",\n",
    "        \"Conscientious\",\n",
    "        \"Balanced\"\n",
    "    ],\n",
    "    \n",
    "    \"education\": [\n",
    "        {\n",
    "            \"degree\": \"PhD Wireless and Mobile Communications\",\n",
    "            \"field\": \"Electrical Engineering, Mathematics and Computer Science (EEMCS)\",\n",
    "            \"institution\": \"Delft University of Technology\",\n",
    "            \"period\": \"2006 – 2010\"\n",
    "        },\n",
    "        {\n",
    "            \"degree\": \"MSc Telecommunications\",\n",
    "            \"institution\": \"Delft University of Technology\",\n",
    "            \"period\": \"2004 – 2006\",\n",
    "            \"honors\": \"Cum Laude, graduated with honors, top 5%\"\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    \"skills\": {\n",
    "        \"technical\": [\"Machine learning\", \"MLOps\", \"AI\", \"Python\"],\n",
    "        \"soft_skills\": [\"Leadership\"]\n",
    "    },\n",
    "    \n",
    "    \"languages\": {\n",
    "        \"English\": \"fully professional\",\n",
    "        \"Dutch\": \"NT2 P.II diploma\"\n",
    "    },\n",
    "    \n",
    "    \"profile\": \"Experienced AI and Data Science leader with 15 years of success delivering scalable ML solutions on AWS and Azure. Skilled in aligning AI strategy with business goals, leading cross-functional teams, and driving innovation across global organizations.\",\n",
    "    \n",
    "    \"work_experience\": [\n",
    "        {\n",
    "            \"title\": \"Senior AI Engineer\",\n",
    "            \"company\": \"Ayvens Digital & IT, Société Générale\",\n",
    "            \"location\": \"Amsterdam\",\n",
    "            \"period\": \"2022 - present\",\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"name\": \"SIMS ML in AWS\",\n",
    "                    \"description\": \"Situation: The original SIMS V1 system used a rigid rules engine that was difficult to maintain and could not scale with evolving business needs. An intelligent, automated solution was required to improve efficiency and support growth. Action: Led the end-to-end design of a scalable ML decision engine on AWS SageMaker, translating business needs into production-ready models with full lifecycle coverage. Result: The solution was deployed in 6 countries and automated 50% of maintenance approvals, significantly reducing delays, lowering costs, and enhancing system scalability.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"ML Enhancement in AWS\",\n",
    "                    \"description\": \"Situation: The ML pipeline lacked structure—ETL was inconsistently managed with PySpark on SageMaker, training was done through scattered Jupyter notebooks, and CI/CD was fragmented between GitLab and Airflow, creating inefficiencies and team dependencies. Action: Redesigned the ML workflow by migrating ETL to Snowflake with Snowpark, replacing Airflow with SageMaker Pipelines, and automating deployment via GitLab CI/CD. Result: Delivered a robust ML platform with unified data processing, streamlined CI/CD, and significantly reduced time-to-deploy and increased team efficiency.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"SIMS ML in Azure\",\n",
    "                    \"description\": \"Situation: In 2024, the team was downsized from 5 to 2 FTEs, losing key support resources. This required a strategic shift to optimize delivery with fewer resources while maintaining AI output. Action: I implemented a E2E ML solutions in Azure Databricks platform. I managed cross-functional teams to ensure smooth execution. Result: Deployed the first production ML model in Azure using Databricks, Unity catalog, MLflow, and Azure DevOps, laying the groundwork for scalable, Azure-native ML deployments across countries.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"AI Alex – AI Agent + MCP (Proof of Concept)\",\n",
    "                    \"description\": \"Situation: Manual maintenance approvals were inefficient and time-consuming, highlighting the need for an interactive, intelligent system to streamline collaboration with garages and reduce human intervention. Action: I led the development of AI Alex, an AI agent built with LLMs, LangChain, and RAG pipelines using Azure Databricks and integrated with MCP tools. Result: The AI agent and MCP solution were successfully deployed in the staging environment, showcasing their potential to automate and improve the existing manual approval process.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"Reference Pricing System (RPS) – ML-Driven Vehicle Price Estimation\",\n",
    "                    \"description\": \"Situation: Manual vehicle pricing across multiple markets was inefficient, inconsistent, and unable to scale— necessitating an ML-based solution to improve speed and accuracy. Action: I designed and deployed an end-to-end ML system using SageMaker, Airflow, and Snowflake, centered around an XGBoost model. The solution automated pricing based on vehicle and market data, with built-in monitoring and retraining, and was fully integrated into business operations. Result: Now live in 23 countries, the system prices over 15,000 vehicles monthly, reducing manual work by 60% and significantly improving speed and accuracy.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Data Scientist, MLE\",\n",
    "            \"company\": \"LeasePlan Digital & IT\",\n",
    "            \"location\": \"Amsterdam\",\n",
    "            \"period\": \"2018 - 2022\",\n",
    "            \"projects\": [\n",
    "                {\n",
    "                    \"name\": \"Mileage Prediction – (Keep Me Safely on the Road)\",\n",
    "                    \"description\": \"Situation: To enable proactive maintenance, accurate mileage forecasts were needed to identify vehicles approaching service thresholds within a 30-day window. Action: Starting from a business use case, I led the development of a proof of concept and scaled it into a full production-grade E2E ML solution. This included building data and ML pipelines, deploying a daily batch inference pipeline, and integrating it into the maintenance system—along with implementing monitoring and alerting to ensure production reliability. Result: The solution now delivers weekly mileage predictions for ~5 million vehicles with approximately 10% MAPE (Mean Absolute Percentage Error). This significantly improved the accuracy of maintenance planning, enabling timely interventions, reducing unplanned downtime, and enhancing overall fleet safety and operational efficiency.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Data Scientist\",\n",
    "            \"company\": \"KPN\",\n",
    "            \"location\": \"Netherlands\",\n",
    "            \"period\": \"2017 - 2018\",\n",
    "            \"responsibilities\": [\n",
    "                \"Internet of Things (IoT) LoRa performance monitoring data analysis\",\n",
    "                \"Time series analysis\",\n",
    "                \"Machine Learning, Deep learning, neural networks architecture and hyperparameter tuning\",\n",
    "                \"Image classification, convolutional neural network (CNN, ConvNet)\",\n",
    "                \"Text classification, recurrent neural network (RNN)\",\n",
    "                \"Recommendation system\"\n",
    "            ],\n",
    "            \"technologies\": [\"Python\", \"pandas\", \"numpy\", \"CNN\", \"RNN\", \"IoT\", \"LoRa\"]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Big Data Engineer, Architect\",\n",
    "            \"company\": \"KPN Business Operation, Big Data Team\",\n",
    "            \"location\": \"Den Haag\",\n",
    "            \"period\": \"2016 - 2017\",\n",
    "            \"responsibilities\": [\n",
    "                \"Data governance\",\n",
    "                \"Big Data solutions\",\n",
    "                \"Hadoop systems\",\n",
    "                \"Data management\"\n",
    "            ],\n",
    "            \"technologies\": [\"Hadoop\", \"Atlas\", \"Ranger\", \"Hive\"]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Project Manager and Innovator\",\n",
    "            \"company\": \"KPN Mobile Innovation Voice & Signaling\",\n",
    "            \"location\": \"Den Haag\",\n",
    "            \"period\": \"2010 - 2016\",\n",
    "            \"responsibilities\": [\n",
    "                \"Relational database and relational data modelling\",\n",
    "                \"LTE/4G and roaming\",\n",
    "                \"MVNO\",\n",
    "                \"Diameter signaling\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    \"years_of_experience\": 15,\n",
    "    \"specializations\": [\n",
    "        \"AI\",\n",
    "        \"Machine Learning\",\n",
    "        \"MLOps\",\n",
    "        \"AWS\",\n",
    "        \"Azure\",\n",
    "        \"Leadership\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Situation: The original SIMS V1 system used a rigid rules engine that was difficult to maintain and could not scale with evolving business needs. An intelligent, automated solution was required to improve efficiency and support growth. Action: Led the end-to-end design of a scalable ML decision engine on AWS SageMaker, translating business needs into production-ready models with full lifecycle coverage. Result: The solution was deployed in 6 countries and automated 50% of maintenance approvals, significantly reducing delays, lowering costs, and enhancing system scalability.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# project. \n",
    "cv_structured[\"work_experience\"][0][\"projects\"][0][\"description\"]\n",
    "\n",
    "# {{ $json[\n",
    "# \"cv_structured\"][\"work_experience\"][0][\n",
    "# \"projects\"][1][\"description\"]}}\n",
    "\n",
    "# {{ $json[\n",
    "# \"cv_structured\"][\"work_experience\"][0][\n",
    "# \"projects\"][2][\"description\"]}}\n",
    "\n",
    "# {{ $json[\n",
    "# \"cv_structured\"][\"work_experience\"][0][\n",
    "# \"projects\"][3][\"description\"]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 project descriptions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Situation: The original SIMS V1 system used a rigid rules engine that was difficult to maintain and could not scale with evolving business needs. An intelligent, automated solution was required to improve efficiency and support growth. Action: Led the end-to-end design of a scalable ML decision engine on AWS SageMaker, translating business needs into production-ready models with full lifecycle coverage. Result: The solution was deployed in 6 countries and automated 50% of maintenance approvals, significantly reducing delays, lowering costs, and enhancing system scalability.',\n",
       " 'Situation: The ML pipeline lacked structure—ETL was inconsistently managed with PySpark on SageMaker, training was done through scattered Jupyter notebooks, and CI/CD was fragmented between GitLab and Airflow, creating inefficiencies and team dependencies. Action: Redesigned the ML workflow by migrating ETL to Snowflake with Snowpark, replacing Airflow with SageMaker Pipelines, and automating deployment via GitLab CI/CD. Result: Delivered a robust ML platform with unified data processing, streamlined CI/CD, and significantly reduced time-to-deploy and increased team efficiency.',\n",
       " 'Situation: In 2024, the team was downsized from 5 to 2 FTEs, losing key support resources. This required a strategic shift to optimize delivery with fewer resources while maintaining AI output. Action: I implemented a E2E ML solutions in Azure Databricks platform. I managed cross-functional teams to ensure smooth execution. Result: Deployed the first production ML model in Azure using Databricks, Unity catalog, MLflow, and Azure DevOps, laying the groundwork for scalable, Azure-native ML deployments across countries.',\n",
       " 'Situation: Manual maintenance approvals were inefficient and time-consuming, highlighting the need for an interactive, intelligent system to streamline collaboration with garages and reduce human intervention. Action: I led the development of AI Alex, an AI agent built with LLMs, LangChain, and RAG pipelines using Azure Databricks and integrated with MCP tools. Result: The AI agent and MCP solution were successfully deployed in the staging environment, showcasing their potential to automate and improve the existing manual approval process.',\n",
       " 'Situation: Manual vehicle pricing across multiple markets was inefficient, inconsistent, and unable to scale— necessitating an ML-based solution to improve speed and accuracy. Action: I designed and deployed an end-to-end ML system using SageMaker, Airflow, and Snowflake, centered around an XGBoost model. The solution automated pricing based on vehicle and market data, with built-in monitoring and retraining, and was fully integrated into business operations. Result: Now live in 23 countries, the system prices over 15,000 vehicles monthly, reducing manual work by 60% and significantly improving speed and accuracy.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick way: Get just the list of descriptions\n",
    "all_descriptions = [proj[\"description\"] for proj in cv_structured[\"work_experience\"][0][\"projects\"]]\n",
    "\n",
    "print(f\"Found {len(all_descriptions)} project descriptions\")\n",
    "all_descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use cases: \n",
    "Logistics Optimization, a just-in-time logistics model, knapsack problems, the traveling salesman, linear programming, and meta-heuristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30th Oct, 2 questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python expression that returns only the topics that appear in BOTH the news article AND the subscription.\n",
    "The expression should:\n",
    "Use the most efficient Python approach (not loops)\n",
    "Return a set of common topics\n",
    "Be a single line expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"topics\"] = [\"radio\", \"television\", \"cable\"]\n",
    "subscription[\"topics\"] = [\"radio\", \"cable\", \"internet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "# Case 2: No common topics\n",
    "news[\"topics\"] = [\"sports\", \"weather\"]\n",
    "subscription[\"topics\"] = [\"radio\", \"cable\"]\n",
    "set(news[\"topics\"]) & set(subscription[\"topics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news_id as key and alist of subscription_id's as value to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "if id not in published_news:\n",
    "    published_news[id] = []\n",
    "published_news[id].append(subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (job_agent)",
   "language": "python",
   "name": "job_agent"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
